{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are those cells doing?\n",
    "\n",
    "### This lesson will download a dataset from the Allen Brain Institute's \"Software Development Kit,\" or SDK.\n",
    "\n",
    "These datasets contain calcium imaging data for various different cell types in the visual cortex of the mouse. It's likely that these cell types have different roles in the visual system -- your mission is to figure out what these roles are. You will choose a visual area, a cell type, and a type of visual stimulus:\n",
    "\n",
    "<img src=\"ExperimentalDesign.png\">  \n",
    "\n",
    "### By the end of this lesson, you will be able to:\n",
    "1. Choose a dataset for a particular cell type and save it locally.\n",
    "2. Plot a stimulus-response curve for one neuron.\n",
    "\n",
    "Additional information on this dataset, and how it was collected, can be found here: http://help.brain-map.org/display/observatory/Data+-+Visual+Coding\n",
    "\n",
    "\n",
    "## 1. Importing toolboxes\n",
    "First, we'll import the necessary toolboxes to run this code. The first chunk of \"import\" lines will bring in some standard toolboxes that we need. For example, \"numpy\" is a toolbox that has functions to work with large arrays (https://en.wikipedia.org/wiki/NumPy). The second chunk of import lines brings in some toolboxes that the Allen Brain Observatory has already packaged, to help users analyze its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported AllenSDK packages.\n"
     ]
    }
   ],
   "source": [
    "# Standard toolboxes\n",
    "import pprint\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import h5py\n",
    "import os\n",
    "# This class uses a 'manifest' to keep track of downloaded data and metadata.  \n",
    "# All downloaded files will be stored relative to the directory holding the manifest\n",
    "# file.  If 'manifest_file' is a relative path (as it is below), it will be \n",
    "# saved relative to your working directory.  It can also be an absolute path.\n",
    "\n",
    "# Allen specific toolboxes\n",
    "import allensdk.brain_observatory.stimulus_info as stim_info\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "from allensdk.brain_observatory.natural_scenes import NaturalScenes\n",
    "from allensdk.brain_observatory.drifting_gratings import DriftingGratings\n",
    "from allensdk.brain_observatory.static_gratings import StaticGratings\n",
    "\n",
    "# We will save the Brain Observatory Cache as a variable, \"boc.\"\n",
    "boc = BrainObservatoryCache(manifest_file='boc/manifest.json')\n",
    "cwd = os.getcwd()\n",
    "print('Successfully imported AllenSDK packages.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get a list of all possible trangenic mouse lines and brain areas\n",
    "Next, we'll print all of the possible Cre lines and brain areas are that we can analyze. You'll need to use these exact names when you're trying to pull a specific one from the dataset.\n",
    "\n",
    "More info on Cre lines can be found here:\n",
    "http://help.brain-map.org/display/observatory/Transgenic+Mouse+Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all cre lines: ['Cux2-CreERT2', 'Emx1-IRES-Cre', 'Fezf2-CreER', 'Nr5a1-Cre', 'Ntsr1-Cre_GN220', 'Pvalb-IRES-Cre', 'Rbp4-Cre_KL100', 'Rorb-IRES2-Cre', 'Scnn1a-Tg3-Cre', 'Slc17a7-IRES2-Cre', 'Sst-IRES-Cre', 'Tlx3-Cre_PL56', 'Vip-IRES-Cre']\n",
      "all brain regions: ['VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISrl']\n"
     ]
    }
   ],
   "source": [
    "# We'll save the list of cre lines as a variable, 'cre-lines'.\n",
    "cre_lines = boc.get_all_cre_lines()\n",
    "print(\"all cre lines: \" + str(cre_lines))\n",
    "\n",
    "# We'll save the list of possible structures as a variable, 'brain_areas'.\n",
    "brain_areas = boc.get_all_targeted_structures()\n",
    "print(\"all brain regions: \" + str(brain_areas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll choose one of these cell lines and brain regions to examine here.\n",
    "\n",
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task:</b>  Choose a visual area and Cre line from the lists above to examine in the rest of the notebook\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's take a look at how ['Rbp4-Cre_KL100'] cells in ['VISp'] respond to drifting_gratings\n"
     ]
    }
   ],
   "source": [
    "# Decide which area and which cre lines you'd like to use.\n",
    "# You need to insert these in the format ['VISp'] or ['Rbp4-Cre'KL100']\n",
    "area = ['VISp']\n",
    "cre_line = ['Rbp4-Cre_KL100']\n",
    "visual_stim = 'drifting_gratings'\n",
    "print(\"Let's take a look at how \" + str(cre_line) + \" cells in \" + str(area) + \" respond to \" + visual_stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the response of cell types to different types of stimuli.\n",
    "Now that we've chosen a cell type and brain area, we need to download a dataset that contains data for that cell type, in that brain area.\n",
    "\n",
    "1. save df/f traces for cells in given area\n",
    "2. get cells and save. \n",
    "3. skip if data already saved. \n",
    "\n",
    "### NOTE: _this will take about 10 minutes per dataset (if it doesn't already exist on your computer)._\n",
    "<p>\n",
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task:</b>  Get the list of all the experiment containers for that area and Cre line combination.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visual_area' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-256da8be08bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_experiment_containers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargeted_structures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvisual_area\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcre_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcre_line\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'visual_area' is not defined"
     ]
    }
   ],
   "source": [
    "exps = boc.get_experiment_containers(targeted_structures=[visual_area], cre_lines=[cre_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-20 13:57:14,010 allensdk.api.api.retrieve_file_over_http INFO     Downloading URL: http://api.brain-map.org/api/v2/well_known_file_download/540020118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'drifting_gratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2bd762036213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdffTraces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dff_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#get traces . dffTraces is cells by time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mstim_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stimulus_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrifting_gratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mcell_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell_specimen_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'drifting_gratings' is not defined"
     ]
    }
   ],
   "source": [
    "interlength = 7 #in frames, 0.25 secs\n",
    "stim_length = 7 #frames, 0.25 secs\n",
    "sweep_length = stim_length + interlength\n",
    "\n",
    "# First, we'll loop through areas (optional, only if you entered 1+ visual area)\n",
    "\n",
    "for aa in range(len(area)):\n",
    "    \n",
    "    this_area = area[aa]\n",
    "    \n",
    "# Then, we'll look through different cre lines (optional, only if you entered 1+ cre line)\n",
    "\n",
    "    for cc in range(len(cre_line)):\n",
    "        \n",
    "        this_cre_line = cre_line[cc]\n",
    "        \n",
    "        # We'll set up some empty variables that we'll fill later.\n",
    "        X_ALL = []\n",
    "        XT_ALL = []\n",
    "        XT_ALL_avg = []\n",
    "        Y_ALL = []\n",
    "        cells_all = []\n",
    "        total_num_cells = 0\n",
    "\n",
    "        exps = boc.get_ophys_experiments(targeted_structures=[this_area],stimuli=[stim_info.DRIFTING_GRATINGS],\n",
    "                                         cre_lines=[this_cre_line],)\n",
    "        \n",
    "        # We could loop through multiple experiments, but for simplicity here, we'll just look at the first one.\n",
    "        # num_expts = len(exps)\n",
    "        num_expts = 1;\n",
    "        \n",
    "        for ee in range(num_expts):\n",
    "            \n",
    "            print(ee)\n",
    "            \n",
    "            exps = boc.get_ophys_experiments(targeted_structures=[this_area],stimuli=[stim_info.DRIFTING_GRATINGS],\n",
    "                                         cre_lines=[this_cre_line])[ee] #for this experiment\n",
    "            expData = boc.get_ophys_experiment_data(exps['id']) # get experiment data - this is the time consuming step\n",
    "            time,dffTraces = expData.get_dff_traces() #get traces . dffTraces is cells by time\n",
    "    \n",
    "            stim_table = expData.get_stimulus_table('drifting_gratings')\n",
    "\n",
    "            cell_ids = expData.get_cell_specimen_ids()\n",
    "            numCells = len(cell_ids)\n",
    "            total_num_cells = numCells + total_num_cells\n",
    "\n",
    "            count = 0\n",
    "\n",
    "            #get 0 ori trials\n",
    "            trial_mask = stim_table.orientation == 0\n",
    "            this_stim_table = stim_table[trial_mask]\n",
    "            trials_per_ori = len(this_stim_table)\n",
    "            XT_zero = np.empty((trials_per_ori,numCells,sweep_length))\n",
    "            XT_zero_avg = np.empty((trials_per_ori,numCells))\n",
    "            stimID_zero = np.empty((trials_per_ori))\n",
    "        \n",
    "            for t in np.arange(0,trials_per_ori):\n",
    "                stimID_zero[t] = 0\n",
    "                for cell in np.arange(0,numCells):\n",
    "                    stim_on = this_stim_table.start.iloc[t-1] \n",
    "                    # start_sweep = stim_on - interlength #start 0.25 secs (7 frames) before stimulus onset\n",
    "                    end_sweep = stim_on + stim_length + interlength #end 0.25 secs (14 frames) after stimulus onset\n",
    "                    trange = np.arange(stim_on,end_sweep)\n",
    "                    XT_zero[t,cell,:] = dffTraces[cell,trange]\n",
    "                    mean_this_cell = np.mean(XT_zero[t,cell,:])\n",
    "                    XT_zero_avg[t,cell] = mean_this_cell\n",
    "                    \n",
    "            #get 90 ori trials\n",
    "            trial_mask = stim_table.orientation == 90\n",
    "            this_stim_table = stim_table[trial_mask]\n",
    "            trials_per_ori = len(this_stim_table)\n",
    "            XT_ninety = np.empty((trials_per_ori,numCells,sweep_length))\n",
    "            XT_ninety_avg = np.empty((trials_per_ori,numCells))\n",
    "            stimID_ninety = np.empty((trials_per_ori))\n",
    "       \n",
    "            for t in np.arange(0,trials_per_ori):\n",
    "                stimID_ninety[t] = 90\n",
    "                for cell in np.arange(0,numCells):\n",
    "                    stim_on = this_stim_table.start.iloc[t-1] \n",
    "                    # start_sweep = stim_on - interlength #start 0.25 secs (7 frames) before stimulus onset\n",
    "                    end_sweep = stim_on + stim_length + interlength #end 0.25 secs (14 frames) after stimulus onset\n",
    "                    # end_sweep = stim_on + stim_length\n",
    "                    # trange = np.arange(stim_on+6,stim_on+10) # range for 200-300 ms post stimulus period\n",
    "                    trange = np.arange(stim_on,end_sweep)\n",
    "                    XT_ninety[t,cell,:] = dffTraces[cell,trange]\n",
    "                    mean_this_cell = np.mean(XT_ninety[t,cell,:])\n",
    "                    XT_ninety_avg[t,cell] = mean_this_cell\n",
    "        \n",
    "            # concatenate 0 and 90 experiments\n",
    "            XT_ALL = np.vstack((XT_zero,XT_ninety))\n",
    "            XT_ALL_avg = np.vstack((XT_zero_avg,XT_ninety_avg))\n",
    "            stimID_ALL = np.hstack((stimID_zero,stimID_ninety))\n",
    "        \n",
    "            print(this_area + ',  ' + this_cre_line + ': ' + str(numCells) + ' cells')\n",
    "            filename = this_area +'_'+ this_cre_line + str(exps['id']) + '_staticOri_data.h5'\n",
    "\n",
    "            #save arrays X_ALL & XT_ALL\n",
    "            with h5py.File(filename,'w') as hf:\n",
    "                hf.create_dataset('X_matrix_time', data=XT_ALL,chunks=True)\n",
    "                hf.create_dataset('XT_stimPeriodavg', data=XT_ALL_avg,chunks=True)\n",
    "                hf.create_dataset('stim_vector', data=stimID_ALL,chunks=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get natural scenes delta F/F\n",
    "1. save df/f traces for cells in given area\n",
    "2. get cells and save. \n",
    "3. skip if data already saved. \n",
    "\n",
    "_this will take a bit of time_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISp,  Rbp4-Cre_KL100: 76 cells\n",
      "VISp,  Cux2-CreERT2: 145 cells\n",
      "VISl,  Rbp4-Cre_KL100: 45 cells\n",
      "VISl,  Cux2-CreERT2: 99 cells\n"
     ]
    }
   ],
   "source": [
    "interlength = 7 #in frames, 0.25 secs\n",
    "stim_length = 7 #frames, 0.25 secs\n",
    "sweep_length = 2*interlength+stim_length #in frames, 1secs\n",
    "\n",
    "for aa in range(len(areas)):\n",
    "    this_area = areas[aa]\n",
    "    \n",
    "    for cc in range(len(cre_lines)):\n",
    "        this_cre_line = cre_lines[cc]\n",
    "        X_ALL = []\n",
    "        XT_ALL = []\n",
    "        Y_ALL = []\n",
    "        cells_all = []\n",
    "        total_num_cells = 0\n",
    "        \n",
    "        exps = boc.get_ophys_experiments(targeted_structures=[this_area],stimuli=[stim_info.NATURAL_SCENES],\n",
    "                                cre_lines=[this_cre_line],)\n",
    "        num_exps = len(exps)\n",
    "\n",
    "        for ee in range(num_exps):\n",
    "            \n",
    "            exps = boc.get_ophys_experiments(targeted_structures=[this_area],stimuli=[stim_info.NATURAL_SCENES],\n",
    "                                             cre_lines=[this_cre_line])[ee]\n",
    "            expData = boc.get_ophys_experiment_data(exps['id'])\n",
    "            time,dffTraces = expData.get_dff_traces() #get traces . dffTraces is cells by time\n",
    "\n",
    "            #118 scenes, each scene presented 50 times. there is a scene labeled -1 in stimulus table, must be blank\n",
    "            stim_table = expData.get_stimulus_table('natural_scenes')\n",
    "            scenes = expData.get_stimulus_template('natural_scenes')\n",
    "            sceneIDs = np.unique(stim_table.frame)\n",
    "            cell_ids = expData.get_cell_specimen_ids()\n",
    "            numCells = len(cell_ids)\n",
    "            total_num_cells = numCells + total_num_cells\n",
    "            nTrials = len(stim_table)\n",
    "            y = np.empty((nTrials))\n",
    "            y[:] = np.nan\n",
    "            trials_per_scene = nTrials/len(sceneIDs)\n",
    "            XT_exp = np.empty((nTrials,numCells,sweep_length))\n",
    "\n",
    "            for scene in sceneIDs:\n",
    "                trial_mask = (stim_table.frame == scene)\n",
    "                this_stim_table = stim_table[trial_mask]\n",
    "                for t in np.arange(1,trials_per_scene+1):\n",
    "                    trial = t + (scene + 1) * trials_per_scene - 1\n",
    "                    y[trial] = scene + 1\n",
    "                    for cell in np.arange(0,numCells):\n",
    "                        stim_on = this_stim_table.start.iloc[t-1] \n",
    "                        start_sweep = stim_on - interlength #start one second (28 frames) before stimulus onset\n",
    "                        end_sweep = stim_on + stim_length + interlength   #end \n",
    "                        trange = np.arange(start_sweep ,end_sweep)\n",
    "                        XT_exp[trial,cell,:] = dffTraces[cell,trange]\n",
    "\n",
    "            #concatenate experiments\n",
    "            if ee == 0:\n",
    "                XT_ALL = XT_exp\n",
    "                Y_ALL = y\n",
    "                cells_all = cell_ids\n",
    "            if ee > 0:\n",
    "                XT_ALL = np.hstack((XT_ALL,XT_exp))\n",
    "                Y_ALL = np.vstack((Y_ALL,y))\n",
    "                cells_all = np.hstack((cells_all,cell_ids))\n",
    "\n",
    "        print(this_area + ',  ' + this_cre_line + ': ' + str(numCells) + ' cells')\n",
    "        filename = this_area +'_'+ this_cre_line + '_' + str(exps['id']) + '_naturalScenes.h5'\n",
    "    \n",
    "        #save arrays X_ALL & XT_ALL -make this into function\n",
    "        with h5py.File(filename,'w') as hf:\n",
    "            hf.create_dataset('X_matrix_time', data=XT_exp,chunks=True)\n",
    "            hf.create_dataset('Y_matrix', data=y,chunks=True)\n",
    "            hf.create_dataset('cell_IDs', data=cell_ids,chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([113806, 113807, 113808, 113809, 113810, 113811, 113812])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
